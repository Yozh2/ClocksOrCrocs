{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clock_or_Crocodile.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow]",
      "language": "python",
      "name": "conda-env-tensorflow-py"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Yozh2/ClocksOrCrocs/blob/master/Clock_or_Crocodile.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "G1TWpbFA_p8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Распознавание часов и крокодилов на изображениях с помощью предварительно обученной нейронной сети VGG16\n",
        "\n",
        "**Источник данных** - [Архив с изображениями](https://drive.google.com/file/d/1JbYmH50iRkMorFk0xNCnwC9xKiB60Mlq/view?usp=sharing), полученный по почте.\n",
        "\n",
        "Для распознавания используется предварительно обученная сверточная нейронная сеть VGG16.\n"
      ]
    },
    {
      "metadata": {
        "id": "X8AV5KvP_p8x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.applications import VGG16\n",
        "from tensorflow.python.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wFvEMeXZBGAr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Перед использованием данных, их необходимо разбить на обучающую, проверочную и тестовую выборки. Делается это при помощи скрипта `data_preparation`"
      ]
    },
    {
      "metadata": {
        "id": "J6lp0GPJ_p86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Каталог с данными для обучения\n",
        "train_dir = './train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = './val'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = './test'\n",
        "# Размеры изображения\n",
        "img_width, img_height = 150, 150\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "# backend Tensorflow, channels_last\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Размер мини-выборки\n",
        "batch_size = 64\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 350\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 75\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JmTZQ4QwiSr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Здесь немного кода, чтобы загружать данные из папки с Google Drive в виртуальную машину Google Colab, на которой производится обучение нейронной сети. На практике оказалось проще загружать архив с датасетом, а потом разархиввировать его внутри."
      ]
    },
    {
      "metadata": {
        "id": "zXxBE85twhrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ffb5742b-8722-439d-b9d7-00de140bf7c0"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "folder_id = '1UKpoczwNIzvZaASLBWn8Z6h2Fyk7v9Tk'\n",
        "\n",
        "def copy_directory(source_id, local_target):\n",
        "    try:\n",
        "        os.makedirs(local_target)\n",
        "    except: \n",
        "        pass\n",
        "    file_list = drive.ListFile({'q': \"'{source_id}' in parents\".format(source_id=source_id)}).GetList()\n",
        "    for f in file_list:\n",
        "        if f[\"title\"].startswith(\".\"):\n",
        "            continue\n",
        "        fname = os.path.join(local_target, f['title'])\n",
        "        if f['mimeType'] == 'application/vnd.google-apps.folder':\n",
        "            copy_directory(f['id'], fname)\n",
        "        else:\n",
        "            f_ = drive.CreateFile({'id': f['id']})\n",
        "            f_.GetContentFile(fname)\n",
        "\n",
        "copy_directory(folder_id, './data')\n",
        "\"\"\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install -U -q PyDrive\\n\\nfrom pydrive.auth import GoogleAuth\\nfrom pydrive.drive import GoogleDrive\\nfrom google.colab import auth\\nfrom oauth2client.client import GoogleCredentials\\n\\n# 1. Authenticate and create the PyDrive client.\\nauth.authenticate_user()\\ngauth = GoogleAuth()\\ngauth.credentials = GoogleCredentials.get_application_default()\\ndrive = GoogleDrive(gauth)\\n\\n# PyDrive reference:\\n# https://googledrive.github.io/PyDrive/docs/build/html/index.html\\n\\n# choose a local (colab) directory to store the data.\\nlocal_download_path = os.path.expanduser(\\'~/data\\')\\ntry:\\n  os.makedirs(local_download_path)\\nexcept: pass\\n\\n# 2. Auto-iterate using the query syntax\\n#    https://developers.google.com/drive/v2/web/search-parameters\\nfolder_id = \\'1UKpoczwNIzvZaASLBWn8Z6h2Fyk7v9Tk\\'\\n\\ndef copy_directory(source_id, local_target):\\n    try:\\n        os.makedirs(local_target)\\n    except: \\n        pass\\n    file_list = drive.ListFile({\\'q\\': \"\\'{source_id}\\' in parents\".format(source_id=source_id)}).GetList()\\n    for f in file_list:\\n        if f[\"title\"].startswith(\".\"):\\n            continue\\n        fname = os.path.join(local_target, f[\\'title\\'])\\n        if f[\\'mimeType\\'] == \\'application/vnd.google-apps.folder\\':\\n            copy_directory(f[\\'id\\'], fname)\\n        else:\\n            f_ = drive.CreateFile({\\'id\\': f[\\'id\\']})\\n            f_.GetContentFile(fname)\\n\\ncopy_directory(folder_id, \\'./data\\')\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "e1yu7AL42M0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Загружаем архив с датасетом"
      ]
    },
    {
      "metadata": {
        "id": "2NMjLCH72Hhm",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d588e37b-b929-43f6-fc57-7a69e74349d7"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a7fb81ba-8e22-4168-b8d7-3cb1cc56ba2e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a7fb81ba-8e22-4168-b8d7-3cb1cc56ba2e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.zip to data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1wIcq_jy1Cl_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Разархивируем датасет в папку"
      ]
    },
    {
      "metadata": {
        "id": "MBJjM0FC0aAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "9c3b98a7-58d2-455f-ca44-512e1c8979e5"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 196\r\n",
            "-rw-r--r-- 1 root root 2745 May  1 22:28 clock.425.png\r\n",
            "-rw-r--r-- 1 root root 2566 May  1 22:28 clock.426.png\r\n",
            "-rw-r--r-- 1 root root 2237 May  1 22:28 clock.427.png\r\n",
            "-rw-r--r-- 1 root root 2518 May  1 22:28 clock.430.png\r\n",
            "-rw-r--r-- 1 root root 2708 May  1 22:28 clock.431.png\r\n",
            "-rw-r--r-- 1 root root 1918 May  1 22:28 clock.432.png\r\n",
            "-rw-r--r-- 1 root root 2422 May  1 22:28 clock.433.png\r\n",
            "-rw-r--r-- 1 root root 2458 May  1 22:28 clock.434.png\r\n",
            "-rw-r--r-- 1 root root 2280 May  1 22:28 clock.435.png\r\n",
            "-rw-r--r-- 1 root root 2689 May  1 22:28 clock.436.png\r\n",
            "-rw-r--r-- 1 root root 2814 May  1 22:28 clock.437.png\r\n",
            "-rw-r--r-- 1 root root 2709 May  1 22:28 clock.438.png\r\n",
            "-rw-r--r-- 1 root root 2795 May  1 22:28 clock.439.png\r\n",
            "-rw-r--r-- 1 root root 2432 May  1 22:28 clock.440.png\r\n",
            "-rw-r--r-- 1 root root 2965 May  1 22:28 clock.441.png\r\n",
            "-rw-r--r-- 1 root root 2259 May  1 22:28 clock.442.png\r\n",
            "-rw-r--r-- 1 root root 2150 May  1 22:28 clock.443.png\r\n",
            "-rw-r--r-- 1 root root 2351 May  1 22:28 clock.444.png\r\n",
            "-rw-r--r-- 1 root root 2268 May  1 22:28 clock.445.png\r\n",
            "-rw-r--r-- 1 root root 1891 May  1 22:28 clock.446.png\r\n",
            "-rw-r--r-- 1 root root 2423 May  1 22:28 clock.447.png\r\n",
            "-rw-r--r-- 1 root root 2691 May  1 22:28 clock.450.png\r\n",
            "-rw-r--r-- 1 root root 2610 May  1 22:28 clock.451.png\r\n",
            "-rw-r--r-- 1 root root 2721 May  1 22:28 clock.452.png\r\n",
            "-rw-r--r-- 1 root root 2461 May  1 22:28 clock.453.png\r\n",
            "-rw-r--r-- 1 root root 1257 May  1 22:28 clock.454.png\r\n",
            "-rw-r--r-- 1 root root 2326 May  1 22:28 clock.455.png\r\n",
            "-rw-r--r-- 1 root root 2651 May  1 22:28 clock.456.png\r\n",
            "-rw-r--r-- 1 root root 2609 May  1 22:28 clock.457.png\r\n",
            "-rw-r--r-- 1 root root 2580 May  1 22:28 clock.468.png\r\n",
            "-rw-r--r-- 1 root root 2835 May  1 22:28 clock.469.png\r\n",
            "-rw-r--r-- 1 root root 2608 May  1 22:28 clock.478.png\r\n",
            "-rw-r--r-- 1 root root 2009 May  1 22:28 clock.479.png\r\n",
            "-rw-r--r-- 1 root root 2053 May  1 22:28 clock.480.png\r\n",
            "-rw-r--r-- 1 root root 2124 May  1 22:28 clock.481.png\r\n",
            "-rw-r--r-- 1 root root 2455 May  1 22:28 clock.482.png\r\n",
            "-rw-r--r-- 1 root root 2300 May  1 22:28 clock.483.png\r\n",
            "-rw-r--r-- 1 root root 2279 May  1 22:28 clock.484.png\r\n",
            "-rw-r--r-- 1 root root 2899 May  1 22:28 clock.485.png\r\n",
            "-rw-r--r-- 1 root root 2473 May  1 22:28 clock.486.png\r\n",
            "-rw-r--r-- 1 root root 2819 May  1 22:28 clock.487.png\r\n",
            "-rw-r--r-- 1 root root 2631 May  1 22:28 clock.490.png\r\n",
            "-rw-r--r-- 1 root root 2900 May  1 22:28 clock.491.png\r\n",
            "-rw-r--r-- 1 root root 2745 May  1 22:28 clock.492.png\r\n",
            "-rw-r--r-- 1 root root 1940 May  1 22:28 clock.493.png\r\n",
            "-rw-r--r-- 1 root root 2339 May  1 22:28 clock.494.png\r\n",
            "-rw-r--r-- 1 root root 2363 May  1 22:28 clock.495.png\r\n",
            "-rw-r--r-- 1 root root 2419 May  1 22:28 clock.496.png\r\n",
            "-rw-r--r-- 1 root root 2741 May  1 22:28 clock.497.png\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ybhg6Alw_p9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Загружаем предварительно обученную нейронную сеть"
      ]
    },
    {
      "metadata": {
        "id": "m47zM99-_p9C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4d6gAmdh_p9H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\"Замораживаем\" веса предварительно обученной нейронной сети VGG16"
      ]
    },
    {
      "metadata": {
        "id": "-Zdg398T_p9K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16_net.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KdBmqWUy_p9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "21aa5c64-c285-4667-8a89-18e95ea3e225"
      },
      "cell_type": "code",
      "source": [
        "vgg16_net.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uDo3kRHl_p9h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Создаем составную нейронную сеть на основе VGG16"
      ]
    },
    {
      "metadata": {
        "id": "UR1eajjL_p9i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Добавляем в модель сеть VGG16 вместо слоя\n",
        "model.add(vgg16_net)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVxyuFMm_p9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a8dda708-155b-4c14-ccc3-ee5178e05f82"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E6nb8vbo_p9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Компилируем составную нейронную сеть"
      ]
    },
    {
      "metadata": {
        "id": "tEuDhc6__p9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cGtVJia0_p90",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Создаем генератор изображений\n",
        "\n",
        "Генератор изображений создается на основе класса ImageDataGenerator. Генератор делит значения всех пикселов изображения на 255."
      ]
    },
    {
      "metadata": {
        "id": "r2LbNaFa_p91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRRTR7zN_p94",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Генератор данных для обучения на основе изображений из каталога"
      ]
    },
    {
      "metadata": {
        "id": "ryLwP6gIvwrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxGw9gLI_p96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "443a7819-0256-48fe-c57a-a48eef48ecd0"
      },
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3610ead826d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     class_mode='binary')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, interpolation)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, interpolation)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m           \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: './data/train'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SiPehQRu_p9_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Генератор данных для проверки на основе изображений из каталога"
      ]
    },
    {
      "metadata": {
        "id": "vxYmEHNR_p-A",
        "colab_type": "code",
        "colab": {},
        "outputId": "1c9d2ee7-b293-44c3-8b19-57e719df6340"
      },
      "cell_type": "code",
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3750 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "to54xq5V_p-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Генератор данных для тестирования на основе изображений из каталога"
      ]
    },
    {
      "metadata": {
        "id": "n8M9S18p_p-F",
        "colab_type": "code",
        "colab": {},
        "outputId": "72af1aae-b3de-4ab7-f316-cdb92a5955ab"
      },
      "cell_type": "code",
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3750 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ch9FwDl-_p-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Обучаем модель с использованием генераторов\n",
        "\n",
        "train_generator - генератор данных для обучения\n",
        "\n",
        "validation_data - генератор данных для проверки"
      ]
    },
    {
      "metadata": {
        "id": "uRUqXyOk_p-J",
        "colab_type": "code",
        "colab": {},
        "outputId": "72297284-1836-4126-9753-26457fd73d88"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "273/273 [==============================] - 462s - loss: 0.2524 - acc: 0.8857 - val_loss: 0.1329 - val_acc: 0.9472\n",
            "Epoch 2/10\n",
            "273/273 [==============================] - 458s - loss: 0.0975 - acc: 0.9630 - val_loss: 0.1237 - val_acc: 0.9512\n",
            "Epoch 3/10\n",
            "273/273 [==============================] - 454s - loss: 0.0606 - acc: 0.9762 - val_loss: 0.0804 - val_acc: 0.9710\n",
            "Epoch 4/10\n",
            "273/273 [==============================] - 454s - loss: 0.0446 - acc: 0.9840 - val_loss: 0.0791 - val_acc: 0.9696\n",
            "Epoch 5/10\n",
            "273/273 [==============================] - 454s - loss: 0.0254 - acc: 0.9915 - val_loss: 0.0976 - val_acc: 0.9699\n",
            "Epoch 6/10\n",
            "273/273 [==============================] - 453s - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0883 - val_acc: 0.9693\n",
            "Epoch 7/10\n",
            "273/273 [==============================] - 451s - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0702 - val_acc: 0.9740\n",
            "Epoch 8/10\n",
            "273/273 [==============================] - 452s - loss: 0.0146 - acc: 0.9951 - val_loss: 0.1078 - val_acc: 0.9704\n",
            "Epoch 9/10\n",
            "273/273 [==============================] - 450s - loss: 0.0049 - acc: 0.9986 - val_loss: 0.1971 - val_acc: 0.9563\n",
            "Epoch 10/10\n",
            "273/273 [==============================] - 451s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1101 - val_acc: 0.9756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras._impl.keras.callbacks.History at 0x259edc89c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "S-mez4zv_p-Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Оцениваем качество работы сети с помощью генератора"
      ]
    },
    {
      "metadata": {
        "id": "DyjVqYB6_p-Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ld1llXYf_p-S",
        "colab_type": "code",
        "colab": {},
        "outputId": "cb3c9d88-4cf0-4cc9-de47-8bb990c2203d"
      },
      "cell_type": "code",
      "source": [
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 97.31%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kuQWobD0_p-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Тонкая настройка сети (fine tuning)"
      ]
    },
    {
      "metadata": {
        "id": "bNfs595A_p-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\"Размораживаем\" последний сверточный блок сети VGG16"
      ]
    },
    {
      "metadata": {
        "id": "34d_-e51_p-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16_net.trainable = True\n",
        "trainable = False\n",
        "for layer in vgg16_net.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        trainable = True\n",
        "    layer.trainable = trainable    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W49ya9W1_p-d",
        "colab_type": "code",
        "colab": {},
        "outputId": "c74559c7-e1a0-4d5b-b1c0-684d7233b003"
      },
      "cell_type": "code",
      "source": [
        "# Проверяем количество обучаемых параметров\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 9,177,089\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uB9PE2pA_p-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNPfC6pJ_p-j",
        "colab_type": "code",
        "colab": {},
        "outputId": "c21a9058-99d5-4d96-ec46-e4b1355f3d03"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "273/273 [==============================] - 184s - loss: 3.6300e-04 - acc: 0.9999 - val_loss: 0.1374 - val_acc: 0.9734\n",
            "Epoch 2/2\n",
            "273/273 [==============================] - 184s - loss: 4.0974e-04 - acc: 0.9999 - val_loss: 0.1476 - val_acc: 0.9759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras._impl.keras.callbacks.History at 0x259efa61be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "WAlDiu5P_p-n",
        "colab_type": "code",
        "colab": {},
        "outputId": "ab7c8294-7a6d-4598-b7dd-3aea5afad037"
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 97.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3IvXcpfp_p-q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}